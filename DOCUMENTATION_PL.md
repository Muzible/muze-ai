# ğŸµ Muzible Muze AI - PeÅ‚na Dokumentacja

> **Text-to-Music Generation with Latent Diffusion & Voice Conditioning**

---

## ğŸ“‘ Spis treÅ›ci

1. [PrzeglÄ…d projektu](#przeglÄ…d-projektu)
2. [Architektura systemu](#architektura-systemu)
3. [Architektura V2](#architektura-v2)
4. [Struktura plikÃ³w](#struktura-plikÃ³w)
5. [Dataset Builder V2](#dataset-builder-v2)
6. [Training Pipeline](#training-pipeline)
7. [Scenariusze uÅ¼ycia](#scenariusze-uÅ¼ycia)
8. [Inference - generowanie muzyki](#inference---generowanie-muzyki)
9. [Model Size Configuration](#model-size-configuration)
10. [FAQ & Troubleshooting](#faq--troubleshooting)

---

## PrzeglÄ…d projektu

**Muzible Muze AI** to system generowania muzyki z tekstu (text-to-music) wykorzystujÄ…cy:

- **Latent Diffusion Model** - generuje muzykÄ™ w skompresowanej przestrzeni latentnej
- **Audio VAE** - kompresuje spektrogramy mel do przestrzeni latentnej
- **T5 Text Encoder** - enkoduje prompty tekstowe
- **Voice Conditioning** - kondycjonuje generacjÄ™ stylem gÅ‚osu artysty
- **HiFi-GAN Vocoder** - konwertuje mel-spektrogramy na audio (32kHz)
- **Voice Cloning (XTTS v2)** - klonuje gÅ‚os do syntezy wokalu

### Dwa tryby gÅ‚osu:

| Tryb | Flaga | Opis | LegalnoÅ›Ä‡ |
|------|-------|------|-----------|
| **Styl artysty** | `--style_of AWOL` | Voice embedding wpÅ‚ywa na "vibe" generowanej muzyki | âœ… Legalne |
| **Klonowanie gÅ‚osu** | `--voice_clone_samples ./vocal.wav` | Syntezuje wokal gÅ‚osem z nagrania | âš ï¸ Wymaga zgody |

---

## Architektura systemu

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Text Prompt   â”‚â”€â”€â”€â–¶â”‚  T5 Encoder     â”‚â”€â”€â”€â–¶â”‚   Text Embed    â”‚
â”‚                 â”‚    â”‚  (768-dim)      â”‚    â”‚   [B, seq, 768] â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚  Voice Sample   â”‚â”€â”€â”€â–¶â”‚  Resemblyzer    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  (optional)     â”‚    â”‚  (256-dim)      â”‚             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
                                                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Noise       â”‚â”€â”€â”€â–¶â”‚   U-Net         â”‚â”€â”€â”€â–¶â”‚   Latent z      â”‚
â”‚   [B, 8, H, W]  â”‚    â”‚  Diffusion      â”‚    â”‚   [B, 8, H, W]  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚  (conditioned)  â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
                                                       â–¼
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚   VAE Decoder   â”‚â”€â”€â”€â–¶â”‚  Mel Spectrogramâ”‚
                       â”‚                 â”‚    â”‚   [B, 1, 80, T] â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                       â”‚
                                                       â–¼
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚   HiFi-GAN     â”‚â”€â”€â”€â–¶â”‚   Audio WAV     â”‚
                       â”‚   (24kHz)       â”‚    â”‚   [samples]     â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Pipeline z voice cloning:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Reference WAV  â”‚â”€â”€â”€â–¶â”‚   Demucs        â”‚â”€â”€â”€â–¶â”‚   Vocals.wav    â”‚
â”‚  (piosenka)     â”‚    â”‚  (htdemucs)     â”‚    â”‚   (czysty wokal)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                       â”‚
                                                       â–¼
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚   XTTS v2       â”‚â”€â”€â”€â–¶â”‚   Synth Vocal   â”‚
                       â”‚  (Coqui TTS)    â”‚    â”‚   (nowy tekst)  â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                    â”‚
â”‚  Generated      â”‚                                    â”‚
â”‚  Instrumental   â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                    â”‚
                                                       â–¼
                                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                              â”‚   Final Mix     â”‚
                                              â”‚   (inst+vocal)  â”‚
                                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¤ Architektura V2 - Voice Stream Attention

### Dlaczego Voice Stream?

W v1 voice embedding byÅ‚ tylko "dodany" do conditioning (`cond = t_emb + voice_cond`). 
To powodowaÅ‚o, Å¼e **wokal byÅ‚ sÅ‚abo zintegrowany z muzykÄ…** - diffusion "widziaÅ‚" gÅ‚os tylko powierzchownie.

**V2 wprowadza Voice Stream Attention** - dedykowany cross-attention na kaÅ¼dym poziomie U-Net:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          JEDEN PROCES DIFFUSION                               â”‚
â”‚                                                                              â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚   â”‚ Voice Embed â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚ Voice Embed â”‚      â”‚
â”‚   â”‚   [B, 256]  â”‚                                      â”‚   [B, 256]  â”‚      â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                                      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚          â”‚                                                    â”‚              â”‚
â”‚          â”‚ ğŸ¤ Voice Stream                                   â”‚ ğŸ¤ Voice    â”‚
â”‚          â”‚    Attention                                      â”‚    Stream    â”‚
â”‚          â–¼                                                    â–¼              â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚  Down Block â”‚â”€â”€â”€â”€â–¶â”‚  Mid Block  â”‚â”€â”€â”€â”€â–¶â”‚  Up Block   â”‚â”€â”‚  Up Block   â”‚  â”‚
â”‚   â”‚  (res 2)    â”‚     â”‚             â”‚     â”‚  (res 4)    â”‚ â”‚  (res 2)    â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚          â–²                   â–²                   â–²              â–²           â”‚
â”‚          â”‚                   â”‚                   â”‚              â”‚           â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”      â”‚           â”‚
â”‚   â”‚Text Attn    â”‚     â”‚Text Attn    â”‚     â”‚Text Attn    â”‚      â”‚           â”‚
â”‚   â”‚(SpatialTF)  â”‚     â”‚(SpatialTF)  â”‚     â”‚(SpatialTF)  â”‚      â”‚           â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚           â”‚
â”‚                                                                 â”‚           â”‚
â”‚                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                            â”‚                                                â”‚
â”‚                            â–¼                                                â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                        â”‚
â”‚                    â”‚ Unified Latentâ”‚                                        â”‚
â”‚                    â”‚ (vocal+music) â”‚                                        â”‚
â”‚                    â”‚  [B, 8, H, W] â”‚                                        â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                        â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Jak dziaÅ‚a VoiceStreamAttention:

```python
class VoiceStreamAttention(nn.Module):
    """
    Gated cross-attention: features â† voice_embedding
    
    1. Features sÄ… query (spatial flatten â†’ sequence)
    2. Voice embedding jest key+value
    3. Cross-attention "informuje" kaÅ¼dy pixel o gÅ‚osie
    4. Gated fusion: x = x + gate * attended_voice
    """
    
    def forward(self, x, voice_emb):
        # x: [B, C, H, W] - feature map
        # voice_emb: [B, voice_dim] - voice embedding
        
        # Flatten spatial â†’ sequence dla attention
        b, c, h, w = x.shape
        q = x.flatten(2).transpose(1, 2)  # [B, H*W, C]
        
        # Voice jako key/value
        kv = self.voice_proj(voice_emb)   # [B, C]
        kv = kv.unsqueeze(1)              # [B, 1, C]
        
        # Cross-attention: kaÅ¼dy pixel "patrzy" na voice
        attended = self.cross_attn(q, kv, kv)  # [B, H*W, C]
        
        # Reshape back to spatial
        attended = attended.transpose(1, 2).reshape(b, c, h, w)
        
        # Gated fusion (model uczy siÄ™ ile voice influence)
        gate = self.voice_gate.sigmoid()
        return x + gate * attended
```

### PorÃ³wnanie v1 vs v2:

| Aspekt | V1 | V2 (Voice Stream) |
|--------|----|--------------------|
| Voice integration | Tylko global addition | Cross-attention na kaÅ¼dym poziomie |
| Voice influence | SÅ‚aba, "hint" | Silna, kaÅ¼dy pixel "widzi" voice |
| Vocal-music coherence | Wokal czasem "obok" muzyki | Wokal zintegrowany z muzykÄ… |
| Learnable | Nie | Tak (gated, model uczy siÄ™ siÅ‚y) |

### UÅ¼ycie w inference:

```bash
# V2 automatycznie uÅ¼ywa Voice Stream
python inference_v2.py \
    --checkpoint checkpoints/diffusion_v2_epoch_100.pt \
    --prompt "Uplifting electronic pop with female vocals" \
    --style_of "Billie Eilish" \
    --output output/billie_style.wav
```

---

## Dataset Builder V2

> ğŸ“˜ **PeÅ‚na dokumentacja:** [docs_v2/DATASET_BUILDER.md](docs_v2/DATASET_BUILDER.md)

### Quick Start

```bash
# PeÅ‚ny build z GPU
python build_dataset_v2.py \
    --audio_dir ./music/fma_small \
    --output ./data_v2/dataset.json \
    --device cuda \
    --batch_size 4
```

### Ekstrakcja cech (v3.1)

| Kategoria | Cechy | Model/NarzÄ™dzie | Wymiar |
|-----------|-------|-----------------|--------|
| ğŸµ Audio | tempo, key, energy, chroma, mel | librosa | - |
| ğŸ¤ Voice | voice embedding | Resemblyzer | 256-dim |
| ğŸ¤ Voice | ECAPA embedding | ECAPA-TDNN | 192-dim |
| ğŸ“ Lyrics | transkrypcja, jÄ™zyk | Whisper large-v3 | - |
| ğŸ”¤ Phonemes | IPA, per-word, timestamps | Gruut/espeak-ng | - |
| ğŸ¼ Segments | verse/chorus/bridge | custom annotator | - |
| ğŸ§  CLAP | audio-text embedding | LAION CLAP | 512-dim |
| ğŸ¸ F0 | fundamental frequency | CREPE/pYIN | - |
| ğŸŒŠ Vibrato | rate, extent | custom | 64-dim |
| ğŸ’¨ Breath | positions | custom | 32-dim |
| ğŸ¤– Prompts | LLM-enhanced | GPT-4o-mini | - |

### Szacunkowe czasy

| Hardware | Czas/track | 1000 trackÃ³w |
|----------|------------|--------------|
| CPU only | ~70s | ~19h |
| RTX 3080 | ~8s | ~2.2h |
| RTX 4090 | ~5s | ~1.4h |

---

## Training Pipeline

### Architektura 3-fazowa

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    MUZE AI TRAINING PIPELINE                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                â”‚
â”‚  â”‚   PHASE 1       â”‚    Audio â†’ Mel â†’ Encoder â†’ z â†’ Decoder â†’ Mel  â”‚
â”‚  â”‚   Audio VAE     â”‚    Loss: Reconstruction + KL + Multi-STFT     â”‚
â”‚  â”‚   (~224M)       â”‚                                                â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                â”‚
â”‚           â”‚                                                         â”‚
â”‚           â”‚ vae_checkpoint                                          â”‚
â”‚           â–¼                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                â”‚
â”‚  â”‚   PHASE 2       â”‚    Track features â†’ Composition plan          â”‚
â”‚  â”‚   Composition   â”‚    (verse/chorus/bridge scheduling)           â”‚
â”‚  â”‚   Planner       â”‚                                                â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                â”‚
â”‚           â”‚                                                         â”‚
â”‚           â”‚ composition_checkpoint                                  â”‚
â”‚           â–¼                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                â”‚
â”‚  â”‚   PHASE 3       â”‚    Noise + Conditions â†’ UNet â†’ Latent â†’ VAE   â”‚
â”‚  â”‚   LDM v2        â”‚    Conditions: text, voice, section, F0...    â”‚
â”‚  â”‚   (~1.3B-6B)    â”‚    Loss: Diffusion + Phoneme Duration         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ§  LDM v2 - SzczegÃ³Å‚owy Diagram Training Pipeline

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                    ğŸµ LDM V2 TRAINING PIPELINE                                               â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                                                              â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â•‘
â•‘  â”‚                                        ğŸ“ DATASET (JSON)                                                â”‚ â•‘
â•‘  â”‚                                                                                                         â”‚ â•‘
â•‘  â”‚  SegmentedTrack {                                                                                       â”‚ â•‘
â•‘  â”‚    "audio_path": "./music/fma/001/track.mp3",                                                          â”‚ â•‘
â•‘  â”‚    "prompt": "Energetic electronic track with heavy bass...",                                          â”‚ â•‘
â•‘  â”‚    "tempo": 128.0,                                                                                      â”‚ â•‘
â•‘  â”‚    "key": "C minor",                         # â†’ key_idx 0-23                                          â”‚ â•‘
â•‘  â”‚    "genre": "electronic",                    # â†’ genres list                                           â”‚ â•‘
â•‘  â”‚    "has_vocals": true,                       # bool                                                    â”‚ â•‘
â•‘  â”‚    "lyrics": "Feel the bass drop...",                                                                  â”‚ â•‘
â•‘  â”‚    "loudness": -14.2,                        # LUFS dB                                                 â”‚ â•‘
â•‘  â”‚    "sentiment_score": 0.7,                   # -1 to 1                                                 â”‚ â•‘
â•‘  â”‚    "artist": "Artist Name",                  # â†’ hash bucket                                           â”‚ â•‘
â•‘  â”‚    "voice_embedding": [256-dim],             # Resemblyzer (from mix)                                  â”‚ â•‘
â•‘  â”‚    "ecapa_embedding": [192-dim],             # ECAPA-TDNN (from separated vocals)                      â”‚ â•‘
â•‘  â”‚    "clap_audio_embedding": [512-dim],        # CLAP audio                                              â”‚ â•‘
â•‘  â”‚    "clap_text_embedding": [512-dim],         # CLAP text (from prompt)                                 â”‚ â•‘
â•‘  â”‚    "f0_contour": [T frames],                 # Fundamental frequency Hz                                â”‚ â•‘
â•‘  â”‚    "f0_coarse": [T frames],                  # Discrete pitch bins (84)                                â”‚ â•‘
â•‘  â”‚    "f0_voiced_mask": [T frames],             # Voiced mask                                             â”‚ â•‘
â•‘  â”‚    "vibrato_rate": 5.5,                      # Hz                                                      â”‚ â•‘
â•‘  â”‚    "vibrato_depth": 30,                      # cents                                                   â”‚ â•‘
â•‘  â”‚    "vibrato_extent": 0.8,                    # 0-1                                                     â”‚ â•‘
â•‘  â”‚    "breath_positions": [2.1, 5.3, ...],      # Breath timings in seconds                               â”‚ â•‘
â•‘  â”‚    "phonemes_ipa": "ËˆfiËl Ã°É™ beÉªs drÉ’p",    # IPA string                                              â”‚ â•‘
â•‘  â”‚    "phoneme_timestamps": [{phoneme, start, end}...],                                                   â”‚ â•‘
â•‘  â”‚    "num_beats": 32,                          # Beat count                                              â”‚ â•‘
â•‘  â”‚    "beat_positions": [0.0, 0.5, 1.0, ...],   # Beat times                                              â”‚ â•‘
â•‘  â”‚    "time_signature": "4/4",                  # Time signature                                          â”‚ â•‘
â•‘  â”‚    "chord_progression": ["Cm", "Gm", ...],   # Chords                                                  â”‚ â•‘
â•‘  â”‚    "segments": [                                                                                        â”‚ â•‘
â•‘  â”‚      {"type": "intro", "start": 0.0, "end": 8.0},                                                      â”‚ â•‘
â•‘  â”‚      {"type": "verse", "start": 8.0, "end": 24.0},                                                     â”‚ â•‘
â•‘  â”‚      {"type": "chorus", "start": 24.0, "end": 40.0},                                                   â”‚ â•‘
â•‘  â”‚      # types: intro/verse/pre_chorus/chorus/post_chorus/bridge/                                        â”‚ â•‘
â•‘  â”‚      #        instrumental/solo/breakdown/buildup/drop/outro/unknown                                   â”‚ â•‘
â•‘  â”‚    ]                                                                                                    â”‚ â•‘
â•‘  â”‚  }                                                                                                      â”‚ â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â•‘
â•‘                                                    â”‚                                                         â•‘
â•‘                                                    â–¼                                                         â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â•‘
â•‘  â”‚                                   ğŸ“¦ SegmentedMusicDataset.__getitem__()                                â”‚ â•‘
â•‘  â”‚                                                                                                         â”‚ â•‘
â•‘  â”‚  1. Load audio segment â†’ Mel spectrogram [1, 128, T]                                                   â”‚ â•‘
â•‘  â”‚  2. VAE encode â†’ Latent z [latent_dim, H, W]                                                           â”‚ â•‘
â•‘  â”‚  3. Prepare conditioning tensors:                                                                       â”‚ â•‘
â•‘  â”‚                                                                                                         â”‚ â•‘
â•‘  â”‚     ğŸ“ Semantic:                                                                                        â”‚ â•‘
â•‘  â”‚     â€¢ text_embedding: T5/CLAP [768 or 512]                                                             â”‚ â•‘
â•‘  â”‚     â€¢ clap_audio_embedding: CLAP audio [512]                                                           â”‚ â•‘
â•‘  â”‚     â€¢ clap_text_embedding: CLAP text [512]                                                             â”‚ â•‘
â•‘  â”‚                                                                                                         â”‚ â•‘
â•‘  â”‚     ğŸ¤ Voice:                                                                                           â”‚ â•‘
â•‘  â”‚     â€¢ voice_embedding: Resemblyzer [256]                                                               â”‚ â•‘
â•‘  â”‚     â€¢ ecapa_embedding: ECAPA-TDNN [192]                                                                â”‚ â•‘
â•‘  â”‚                                                                                                         â”‚ â•‘
â•‘  â”‚     ğŸ¼ Structure (13 types):                                                                            â”‚ â•‘
â•‘  â”‚     â€¢ section_type: intro/verse/pre_chorus/chorus/post_chorus/bridge/                                  â”‚ â•‘
â•‘  â”‚                     instrumental/solo/breakdown/buildup/drop/outro/unknown                              â”‚ â•‘
â•‘  â”‚     â€¢ position_in_song: float [0.0-1.0]                                                                â”‚ â•‘
â•‘  â”‚     â€¢ tempo: normalized float                                                                          â”‚ â•‘
â•‘  â”‚     â€¢ key_idx: int [0-23]                                                                              â”‚ â•‘
â•‘  â”‚                                                                                                         â”‚ â•‘
â•‘  â”‚     ğŸ”Š Audio metadata (v3):                                                                             â”‚ â•‘
â•‘  â”‚     â€¢ loudness: dB, energy: float, has_vocals: bool                                                    â”‚ â•‘
â•‘  â”‚     â€¢ sentiment_score: [-1, 1], genres: List[str], artist: str                                         â”‚ â•‘
â•‘  â”‚                                                                                                         â”‚ â•‘
â•‘  â”‚     ğŸ¥ Beat/Chord (v2):                                                                                 â”‚ â•‘
â•‘  â”‚     â€¢ num_beats, beat_positions, time_signature, current_chord                                         â”‚ â•‘
â•‘  â”‚                                                                                                         â”‚ â•‘
â•‘  â”‚     ğŸµ Pitch (v3):                                                                                      â”‚ â•‘
â•‘  â”‚     â€¢ f0: [T_f0], f0_coarse: [T_f0], f0_voiced_mask: [T_f0]                                           â”‚ â•‘
â•‘  â”‚                                                                                                         â”‚ â•‘
â•‘  â”‚     ğŸ¤ Singing (v3.1):                                                                                  â”‚ â•‘
â•‘  â”‚     â€¢ vibrato_rate/depth/extent, breath_positions, phoneme_timestamps                                  â”‚ â•‘
â•‘  â”‚                                                                                                         â”‚ â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â•‘
â•‘                                                    â”‚                                                         â•‘
â•‘                                                    â–¼                                                         â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                        ğŸ‹ï¸ DIFFUSION TRAINER                                                 â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                                                              â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â•‘
â•‘  â”‚                                    NOISE SCHEDULING                                                     â”‚ â•‘
â•‘  â”‚                                                                                                         â”‚ â•‘
â•‘  â”‚   Latent zâ‚€ [B, 128, H, W]                                                                             â”‚ â•‘
â•‘  â”‚        â”‚                                                                                                â”‚ â•‘
â•‘  â”‚        â”‚  t ~ Uniform(0, T)   Îµ ~ N(0, I)                                                              â”‚ â•‘
â•‘  â”‚        â”‚                                                                                                â”‚ â•‘
â•‘  â”‚        â–¼                                                                                                â”‚ â•‘
â•‘  â”‚   zâ‚œ = âˆšÎ±â‚œ Â· zâ‚€ + âˆš(1-Î±â‚œ) Â· Îµ    (Forward diffusion)                                                  â”‚ â•‘
â•‘  â”‚                                                                                                         â”‚ â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â•‘
â•‘                                                    â”‚                                                         â•‘
â•‘                                                    â–¼                                                         â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ CONDITIONING PREPARATION â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â•‘
â•‘  â”‚                                                                                                       â”‚   â•‘
â•‘  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚   â•‘
â•‘  â”‚  â”‚                           1ï¸âƒ£ TEXT CONDITIONING (semantic control)                               â”‚ â”‚   â•‘
â•‘  â”‚  â”‚                                                                                                 â”‚ â”‚   â•‘
â•‘  â”‚  â”‚   prompt "Energetic electronic..." â”€â”€â†’ T5 Encoder â”€â”€â†’ text_emb [B, seq, 768]                   â”‚ â”‚   â•‘
â•‘  â”‚  â”‚                                           â”‚                                                     â”‚ â”‚   â•‘
â•‘  â”‚  â”‚                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                        â”‚ â”‚   â•‘
â•‘  â”‚  â”‚                              â”‚ Cross-attention in UNet â”‚                                        â”‚ â”‚   â•‘
â•‘  â”‚  â”‚                              â”‚ Q: features, K/V: text  â”‚                                        â”‚ â”‚   â•‘
â•‘  â”‚  â”‚                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                        â”‚ â”‚   â•‘
â•‘  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚   â•‘
â•‘  â”‚                                                                                                       â”‚   â•‘
â•‘  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚   â•‘
â•‘  â”‚  â”‚                          2ï¸âƒ£ VOICE CONDITIONING (speaker identity)                               â”‚ â”‚   â•‘
â•‘  â”‚  â”‚                                                                                                 â”‚ â”‚   â•‘
â•‘  â”‚  â”‚   voice_emb [B, 256] â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚ â”‚   â•‘
â•‘  â”‚  â”‚   (Resemblyzer - mix)     â”‚     â”‚            VoiceStreamAttention                    â”‚         â”‚ â”‚   â•‘
â•‘  â”‚  â”‚                           â”œâ”€â”€â”€â”€â–¶â”‚  Gated cross-attention at each UNet level         â”‚         â”‚ â”‚   â•‘
â•‘  â”‚  â”‚   ecapa_emb [B, 192] â”€â”€â”€â”€â”€â”˜     â”‚  x = x + gate Â· CrossAttn(x, voice)               â”‚         â”‚ â”‚   â•‘
â•‘  â”‚  â”‚   (ECAPA - vocals)              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚ â”‚   â•‘
â•‘  â”‚  â”‚                                                                                                 â”‚ â”‚   â•‘
â•‘  â”‚  â”‚   ğŸ’¡ Voice Stream = dedicated cross-attention at EVERY level for deep voice integration        â”‚ â”‚   â•‘
â•‘  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚   â•‘
â•‘  â”‚                                                                                                       â”‚   â•‘
â•‘  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚   â•‘
â•‘  â”‚  â”‚                           3ï¸âƒ£ CLAP CONDITIONING (audio-text alignment)                           â”‚ â”‚   â•‘
â•‘  â”‚  â”‚                                                                                                 â”‚ â”‚   â•‘
â•‘  â”‚  â”‚   clap_audio_emb [B, 512] â”€â”€â†’ Project â”€â”€â†’ [B, 512] â”€â”€â†’ Add to time embedding                   â”‚ â”‚   â•‘
â•‘  â”‚  â”‚                                                                                                 â”‚ â”‚   â•‘
â•‘  â”‚  â”‚   ğŸ’¡ CLAP provides audio-grounded semantic information                                          â”‚ â”‚   â•‘
â•‘  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚   â•‘
â•‘  â”‚                                                                                                       â”‚   â•‘
â•‘  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚   â•‘
â•‘  â”‚  â”‚                           4ï¸âƒ£ SECTION CONDITIONING (structure awareness)                         â”‚ â”‚   â•‘
â•‘  â”‚  â”‚                                                                                                 â”‚ â”‚   â•‘
â•‘  â”‚  â”‚   section_type [one-hot 13]â”€â”€â”¬â”€â”€â†’ SectionConditioningModule â”€â”€â†’ [B, 1024]                      â”‚ â”‚   â•‘
â•‘  â”‚  â”‚   position_in_song [float]  â”€â”¤                                      â”‚                           â”‚ â”‚   â•‘
â•‘  â”‚  â”‚   energy, tempo [float]     â”€â”¤                                      â–¼                           â”‚ â”‚   â•‘
â•‘  â”‚  â”‚   key_idx [int 0-23]        â”€â”¤                              Add to time embedding               â”‚ â”‚   â•‘
â•‘  â”‚  â”‚   loudness, has_vocals      â”€â”¤                                                                  â”‚ â”‚   â•‘
â•‘  â”‚  â”‚   sentiment, genres, artist â”€â”˜                                                                  â”‚ â”‚   â•‘
â•‘  â”‚  â”‚                                                                                                 â”‚ â”‚   â•‘
â•‘  â”‚  â”‚   ğŸ’¡ Section = intro/verse/pre_chorus/chorus/post_chorus/bridge/instrumental/                   â”‚ â”‚   â•‘
â•‘  â”‚  â”‚                solo/breakdown/buildup/drop/outro/unknown                                        â”‚ â”‚   â•‘
â•‘  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚   â•‘
â•‘  â”‚                                                                                                       â”‚   â•‘
â•‘  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚   â•‘
â•‘  â”‚  â”‚                           5ï¸âƒ£ PITCH/F0 CONDITIONING (melody)                                     â”‚ â”‚   â•‘
â•‘  â”‚  â”‚                                                                                                 â”‚ â”‚   â•‘
â•‘  â”‚  â”‚   f0_contour [B, T] â”€â”€â†’ F0Encoder â”€â”€â†’ [B, 64, T'] â”€â”€â†’ Concatenate to UNet features             â”‚ â”‚   â•‘
â•‘  â”‚  â”‚                             â”‚                                                                   â”‚ â”‚   â•‘
â•‘  â”‚  â”‚                             â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚ â”‚   â•‘
â•‘  â”‚  â”‚                             â””â”€â”€â”‚ Log scale + Conv1D + Interpolate to match size  â”‚             â”‚ â”‚   â•‘
â•‘  â”‚  â”‚                                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚ â”‚   â•‘
â•‘  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚   â•‘
â•‘  â”‚                                                                                                       â”‚   â•‘
â•‘  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚   â•‘
â•‘  â”‚  â”‚                           6ï¸âƒ£ SINGING CONDITIONING (vibrato + breath + phonemes)                 â”‚ â”‚   â•‘
â•‘  â”‚  â”‚                                                                                                 â”‚ â”‚   â•‘
â•‘  â”‚  â”‚   vibrato_features [B, 64] â”€â”€â†’ VibratoEncoder â”€â”€â†’ [B, 64] â”€â”€â”                                  â”‚ â”‚   â•‘
â•‘  â”‚  â”‚                                                             â”‚                                   â”‚ â”‚   â•‘
â•‘  â”‚  â”‚   breath_positions [B, 32] â”€â”€â†’ BreathEncoder â”€â”€â†’ [B, 32] â”€â”€â”€â”¼â”€â”€â†’ Concat â†’ Add to time emb      â”‚ â”‚   â•‘
â•‘  â”‚  â”‚                                                             â”‚                                   â”‚ â”‚   â•‘
â•‘  â”‚  â”‚   phoneme_seq [B, N, 64] â”€â”€â†’ PhonemeEncoder â”€â”€â†’ [B, N, 64] â”€â”˜                                  â”‚ â”‚   â•‘
â•‘  â”‚  â”‚                                                                                                 â”‚ â”‚   â•‘
â•‘  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚   â•‘
â•‘  â”‚                                                                                                       â”‚   â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â•‘
â•‘                                                    â”‚                                                         â•‘
â•‘                                                    â–¼                                                         â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                     ğŸ§  UNet V2 FORWARD PASS                                                  â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                                                              â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â•‘
â•‘  â”‚                                                                                                         â”‚ â•‘
â•‘  â”‚   zâ‚œ [B, 128, H, W]     t_emb [B, time_dim]     context [B, seq, 768]     voice [B, 256]               â”‚ â•‘
â•‘  â”‚        â”‚                      â”‚                       â”‚                       â”‚                         â”‚ â•‘
â•‘  â”‚        â”‚                      â”‚                       â”‚                       â”‚                         â”‚ â•‘
â•‘  â”‚        â–¼                      â–¼                       â”‚                       â”‚                         â”‚ â•‘
â•‘  â”‚   â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—     â”‚ â•‘
â•‘  â”‚   â•‘                              ENCODER (Downsample)                                             â•‘     â”‚ â•‘
â•‘  â”‚   â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£     â”‚ â•‘
â•‘  â”‚   â•‘                                                                                               â•‘     â”‚ â•‘
â•‘  â”‚   â•‘   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â•‘     â”‚ â•‘
â•‘  â”‚   â•‘   â”‚                            Down Block (level 0)                                     â”‚     â•‘     â”‚ â•‘
â•‘  â”‚   â•‘   â”‚                                                                                     â”‚     â•‘     â”‚ â•‘
â•‘  â”‚   â•‘   â”‚   [B, 128, H, W] â”€â”€â†’ ResBlock(t_emb) â”€â”€â†’ ResBlock(t_emb)                           â”‚     â•‘     â”‚ â•‘
â•‘  â”‚   â•‘   â”‚                            â”‚                                                        â”‚     â•‘     â”‚ â•‘
â•‘  â”‚   â•‘   â”‚                            â–¼                                                        â”‚     â•‘     â”‚ â•‘
â•‘  â”‚   â•‘   â”‚   ğŸ¤ VoiceStreamAttention â† voice_emb                                              â”‚     â•‘     â”‚ â•‘
â•‘  â”‚   â•‘   â”‚                            â”‚                                                        â”‚     â•‘     â”‚ â•‘
â•‘  â”‚   â•‘   â”‚                            â–¼                                                        â”‚     â•‘     â”‚ â•‘
â•‘  â”‚   â•‘   â”‚                      Downsample 2Ã—                                                  â”‚     â•‘     â”‚ â•‘
â•‘  â”‚   â•‘   â”‚                                                                                     â”‚     â•‘     â”‚ â•‘
â•‘  â”‚   â•‘   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â•‘     â”‚ â•‘
â•‘  â”‚   â•‘                                         â”‚                                                     â•‘     â”‚ â•‘
â•‘  â”‚   â•‘                                         â–¼                                                     â•‘     â”‚ â•‘
â•‘  â”‚   â•‘   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â•‘     â”‚ â•‘
â•‘  â”‚   â•‘   â”‚                            Down Block (level 1) + SpatialTransformer                â”‚     â•‘     â”‚ â•‘
â•‘  â”‚   â•‘   â”‚                                                                                     â”‚     â•‘     â”‚ â•‘
â•‘  â”‚   â•‘   â”‚   [B, 320, H/2, W/2] â”€â”€â†’ ResBlock â”€â”€â†’ SpatialTransformer â†â”€ context (text)         â”‚     â•‘     â”‚ â•‘
â•‘  â”‚   â•‘   â”‚                                              â”‚                                      â”‚     â•‘     â”‚ â•‘
â•‘  â”‚   â•‘   â”‚                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚     â•‘     â”‚ â•‘
â•‘  â”‚   â•‘   â”‚                     â”‚          SpatialTransformer                       â”‚           â”‚     â•‘     â”‚ â•‘
â•‘  â”‚   â•‘   â”‚                     â”‚  1. Self-Attention (spatial)                      â”‚           â”‚     â•‘     â”‚ â•‘
â•‘  â”‚   â•‘   â”‚                     â”‚  2. Cross-Attention (Q: features, K/V: text)      â”‚           â”‚     â•‘     â”‚ â•‘
â•‘  â”‚   â•‘   â”‚                     â”‚  3. FeedForward                                   â”‚           â”‚     â•‘     â”‚ â•‘
â•‘  â”‚   â•‘   â”‚                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚     â•‘     â”‚ â•‘
â•‘  â”‚   â•‘   â”‚                                              â”‚                                      â”‚     â•‘     â”‚ â•‘
â•‘  â”‚   â•‘   â”‚   ğŸ¤ VoiceStreamAttention â† voice_emb       â”‚                                      â”‚     â•‘     â”‚ â•‘
â•‘  â”‚   â•‘   â”‚                                              â–¼                                      â”‚     â•‘     â”‚ â•‘
â•‘  â”‚   â•‘   â”‚                                       Downsample 2Ã—                                 â”‚     â•‘     â”‚ â•‘
â•‘  â”‚   â•‘   â”‚                                                                                     â”‚     â•‘     â”‚ â•‘
â•‘  â”‚   â•‘   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â•‘     â”‚ â•‘
â•‘  â”‚   â•‘                                         â”‚                                                     â•‘     â”‚ â•‘
â•‘  â”‚   â•‘                            ... more down blocks ...                                           â•‘     â”‚ â•‘
â•‘  â”‚   â•‘                                                                                               â•‘     â”‚ â•‘
â•‘  â”‚   â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•     â”‚ â•‘
â•‘  â”‚                                         â”‚                                                               â”‚ â•‘
â•‘  â”‚                                         â–¼                                                               â”‚ â•‘
â•‘  â”‚   â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—     â”‚ â•‘
â•‘  â”‚   â•‘                              MIDDLE BLOCK (Bottleneck)                                        â•‘     â”‚ â•‘
â•‘  â”‚   â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£     â”‚ â•‘
â•‘  â”‚   â•‘                                                                                               â•‘     â”‚ â•‘
â•‘  â”‚   â•‘   [B, 1280, H/8, W/8] â”€â”€â†’ ResBlock â”€â”€â†’ SpatialTransformer â”€â”€â†’ ResBlock                       â•‘     â”‚ â•‘
â•‘  â”‚   â•‘                                              â”‚                                                â•‘     â”‚ â•‘
â•‘  â”‚   â•‘                         ğŸ¤ VoiceStreamAttention â† voice_emb                                  â•‘     â”‚ â•‘
â•‘  â”‚   â•‘                                                                                               â•‘     â”‚ â•‘
â•‘  â”‚   â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•     â”‚ â•‘
â•‘  â”‚                                         â”‚                                                               â”‚ â•‘
â•‘  â”‚                                         â–¼                                                               â”‚ â•‘
â•‘  â”‚   â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—     â”‚ â•‘
â•‘  â”‚   â•‘                              DECODER (Upsample) + Skip Connections                            â•‘     â”‚ â•‘
â•‘  â”‚   â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£     â”‚ â•‘
â•‘  â”‚   â•‘                                                                                               â•‘     â”‚ â•‘
â•‘  â”‚   â•‘   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â•‘     â”‚ â•‘
â•‘  â”‚   â•‘   â”‚                            Up Block (level 2) + Skip                                â”‚     â•‘     â”‚ â•‘
â•‘  â”‚   â•‘   â”‚                                                                                     â”‚     â•‘     â”‚ â•‘
â•‘  â”‚   â•‘   â”‚   [middle] + [skip from down_2] â”€â”€â†’ Concat â”€â”€â†’ ResBlock â”€â”€â†’ SpatialTransformer     â”‚     â•‘     â”‚ â•‘
â•‘  â”‚   â•‘   â”‚                                                       â”‚                             â”‚     â•‘     â”‚ â•‘
â•‘  â”‚   â•‘   â”‚   ğŸ¤ VoiceStreamAttention â† voice_emb                â”‚                             â”‚     â•‘     â”‚ â•‘
â•‘  â”‚   â•‘   â”‚                                                       â–¼                             â”‚     â•‘     â”‚ â•‘
â•‘  â”‚   â•‘   â”‚                                                 Upsample 2Ã—                         â”‚     â•‘     â”‚ â•‘
â•‘  â”‚   â•‘   â”‚                                                                                     â”‚     â•‘     â”‚ â•‘
â•‘  â”‚   â•‘   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â•‘     â”‚ â•‘
â•‘  â”‚   â•‘                                         â”‚                                                     â•‘     â”‚ â•‘
â•‘  â”‚   â•‘                            ... more up blocks ...                                             â•‘     â”‚ â•‘
â•‘  â”‚   â•‘                                                                                               â•‘     â”‚ â•‘
â•‘  â”‚   â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•     â”‚ â•‘
â•‘  â”‚                                         â”‚                                                               â”‚ â•‘
â•‘  â”‚                                         â–¼                                                               â”‚ â•‘
â•‘  â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                                               â”‚ â•‘
â•‘  â”‚   â”‚  Final Conv         â”‚ â”€â”€â†’ ÎµÌ‚ [B, 128, H, W]  (predicted noise)                                      â”‚ â•‘
â•‘  â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                                               â”‚ â•‘
â•‘  â”‚                                                                                                         â”‚ â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â•‘
â•‘                                       â”‚                                                                      â•‘
â•‘                                       â–¼                                                                      â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â•‘
â•‘  â”‚                                    ğŸ“‰ LOSS COMPUTATION                                                  â”‚ â•‘
â•‘  â”‚                                                                                                         â”‚ â•‘
â•‘  â”‚   Îµ (ground truth noise)                                                                                â”‚ â•‘
â•‘  â”‚        â”‚                                                                                                â”‚ â•‘
â•‘  â”‚        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚ â•‘
â•‘  â”‚        â”‚  â”‚                         Diffusion Loss                                       â”‚              â”‚ â•‘
â•‘  â”‚        â”‚  â”‚                                                                              â”‚              â”‚ â•‘
â•‘  â”‚        â”‚  â”‚  L_diffusion = MSE(Îµ, ÎµÌ‚)    (Mean Squared Error between noise)             â”‚              â”‚ â•‘
â•‘  â”‚        â”‚  â”‚                                                                              â”‚              â”‚ â•‘
â•‘  â”‚        â”‚  â”‚  + Optional: v-prediction loss, SNR weighting                               â”‚              â”‚ â•‘
â•‘  â”‚        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚ â•‘
â•‘  â”‚        â–¼                                                                                                â”‚ â•‘
â•‘  â”‚   loss = L_diffusion                                                                                    â”‚ â•‘
â•‘  â”‚                                                                                                         â”‚ â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â•‘
â•‘                                       â”‚                                                                      â•‘
â•‘                                       â–¼                                                                      â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â•‘
â•‘  â”‚                                    âš¡ OPTIMIZATION                                                       â”‚ â•‘
â•‘  â”‚                                                                                                         â”‚ â•‘
â•‘  â”‚   loss.backward()  â”€â”€â†’  (AMP scaler if mixed_precision)                                                â”‚ â•‘
â•‘  â”‚        â”‚                                                                                                â”‚ â•‘
â•‘  â”‚        â–¼                                                                                                â”‚ â•‘
â•‘  â”‚   grad_clip (max_norm=1.0)                                                                              â”‚ â•‘
â•‘  â”‚        â”‚                                                                                                â”‚ â•‘
â•‘  â”‚        â–¼                                                                                                â”‚ â•‘
â•‘  â”‚   optimizer.step() (AdamW, lr=1e-4, weight_decay=0.01)                                                  â”‚ â•‘
â•‘  â”‚        â”‚                                                                                                â”‚ â•‘
â•‘  â”‚        â–¼                                                                                                â”‚ â•‘
â•‘  â”‚   EMA update (momentum=0.9999)                                                                          â”‚ â•‘
â•‘  â”‚                                                                                                         â”‚ â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â•‘
â•‘                                                                                                              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                    ğŸ“Š LDM V2 CONDITIONING SUMMARY (v3.1)                                     â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                                                              â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â•‘
â•‘  â”‚         SOURCE              â”‚          PROCESSING          â”‚              DESTINATION                  â”‚  â•‘
â•‘  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â•‘
â•‘  â”‚                             â”‚                              â”‚                                           â”‚  â•‘
â•‘  â”‚  ğŸ“ TEXT:                   â”‚                              â”‚                                           â”‚  â•‘
â•‘  â”‚  prompt                     â”‚  T5 / CLAP encoder           â”‚  Cross-attention in SpatialTransformer   â”‚  â•‘
â•‘  â”‚                             â”‚  [768 or 512 dim]            â”‚                                           â”‚  â•‘
â•‘  â”‚                             â”‚                              â”‚                                           â”‚  â•‘
â•‘  â”‚  ğŸ¤ VOICE (dual):           â”‚                              â”‚                                           â”‚  â•‘
â•‘  â”‚  voice_embedding [256]      â”‚  VoiceStreamAttention        â”‚  Gated cross-attn at EVERY level         â”‚  â•‘
â•‘  â”‚  (Resemblyzer - mix)        â”‚  + VoiceEmbeddingFusion      â”‚  (fused 256+192 â†’ 256)                    â”‚  â•‘
â•‘  â”‚  voice_emb_separated [192]  â”‚                              â”‚                                           â”‚  â•‘
â•‘  â”‚  (ECAPA-TDNN - vocals)      â”‚                              â”‚                                           â”‚  â•‘
â•‘  â”‚                             â”‚                              â”‚                                           â”‚  â•‘
â•‘  â”‚  ğŸ”Š CLAP (audio+text):      â”‚                              â”‚                                           â”‚  â•‘
â•‘  â”‚  clap_audio_embedding [512] â”‚  ClapProjection (fused)      â”‚  â†’ 128-dim added to section cond          â”‚  â•‘
â•‘  â”‚  clap_text_embedding [512]  â”‚                              â”‚                                           â”‚  â•‘
â•‘  â”‚                             â”‚                              â”‚                                           â”‚  â•‘
â•‘  â”‚  ğŸ¼ STRUCTURE (v3):         â”‚                              â”‚                                           â”‚  â•‘
â•‘  â”‚  section_type [one-hot 13]  â”‚  SectionConditioningModule   â”‚  â†’ 1024-dim conditioning vector           â”‚  â•‘
â•‘  â”‚  position [float]           â”‚  (fusion MLP)                â”‚  Added to time embedding                  â”‚  â•‘
â•‘  â”‚  energy, tempo [float]      â”‚                              â”‚                                           â”‚  â•‘
â•‘  â”‚  key_idx [int 0-23]         â”‚                              â”‚                                           â”‚  â•‘
â•‘  â”‚  loudness [dB]              â”‚                              â”‚                                           â”‚  â•‘
â•‘  â”‚  has_vocals [bool]          â”‚                              â”‚                                           â”‚  â•‘
â•‘  â”‚  sentiment_score [-1..1]    â”‚                              â”‚                                           â”‚  â•‘
â•‘  â”‚  genres [List[List[str]]]   â”‚                              â”‚                                           â”‚  â•‘
â•‘  â”‚  artists [List[str]]        â”‚                              â”‚                                           â”‚  â•‘
â•‘  â”‚                             â”‚                              â”‚                                           â”‚  â•‘
â•‘  â”‚  ğŸ¥ BEAT (v2):              â”‚                              â”‚                                           â”‚  â•‘
â•‘  â”‚  num_beats [int]            â”‚  BeatEmbedding               â”‚  â†’ 64-dim                                 â”‚  â•‘
â•‘  â”‚  beat_positions [List]      â”‚                              â”‚                                           â”‚  â•‘
â•‘  â”‚  time_signature [str]       â”‚                              â”‚                                           â”‚  â•‘
â•‘  â”‚                             â”‚                              â”‚                                           â”‚  â•‘
â•‘  â”‚  ğŸ¸ CHORD (v2):             â”‚                              â”‚                                           â”‚  â•‘
â•‘  â”‚  current_chord [str]        â”‚  ChordEmbedding              â”‚  â†’ 64-dim                                 â”‚  â•‘
â•‘  â”‚                             â”‚                              â”‚                                           â”‚  â•‘
â•‘  â”‚  ğŸµ MELODY (v3):            â”‚                              â”‚                                           â”‚  â•‘
â•‘  â”‚  f0 [B, T] Hz               â”‚  PitchEncoder                â”‚  â†’ 64-dim                                 â”‚  â•‘
â•‘  â”‚  f0_coarse [B, T] bins      â”‚  (continuous + discrete)     â”‚  Concatenated to UNet features            â”‚  â•‘
â•‘  â”‚  f0_voiced_mask [B, T]      â”‚                              â”‚                                           â”‚  â•‘
â•‘  â”‚                             â”‚                              â”‚                                           â”‚  â•‘
â•‘  â”‚  ğŸ¤ SINGING (v3.1):         â”‚                              â”‚                                           â”‚  â•‘
â•‘  â”‚  vibrato_rate/depth/extent  â”‚  VibratoEncoder              â”‚  â†’ 64-dim                                 â”‚  â•‘
â•‘  â”‚  breath_positions [List]    â”‚  BreathEncoder               â”‚  â†’ 32-dim                                 â”‚  â•‘
â•‘  â”‚  phoneme_timestamps [List]  â”‚  PhonemeTimestampEncoder     â”‚  â†’ 64-dim                                 â”‚  â•‘
â•‘  â”‚  phonemes_ipa [str]         â”‚  PhonemeEncoder              â”‚  â†’ 128-dim + durations                    â”‚  â•‘
â•‘  â”‚                             â”‚                              â”‚                                           â”‚  â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â•‘
â•‘                                                                                                              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---

## ğŸµ LDM V2 - Inference Pipeline

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                    ğŸµ LDM V2 INFERENCE PIPELINE                                              â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                                                              â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â•‘
â•‘  â”‚                                        ğŸ“ USER INPUT                                                    â”‚ â•‘
â•‘  â”‚                                                                                                         â”‚ â•‘
â•‘  â”‚  python inference_v2.py \                                                                                â”‚ â•‘
â•‘  â”‚      --prompt "Energetic electronic dance track with heavy bass" \                                     â”‚ â•‘
â•‘  â”‚      --duration 30 \                                                                                    â”‚ â•‘
â•‘  â”‚      --style_of "./reference_artist.wav" \      # Optional: voice style                                â”‚ â•‘
â•‘  â”‚      --lyrics "Feel the bass drop..." \          # Optional: for singing                               â”‚ â•‘
â•‘  â”‚      --template verse_chorus \                   # Optional: structure template                        â”‚ â•‘
â•‘  â”‚      --output ./output/generated.wav                                                                    â”‚ â•‘
â•‘  â”‚                                                                                                         â”‚ â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â•‘
â•‘                                                    â”‚                                                         â•‘
â•‘                                                    â–¼                                                         â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â•‘
â•‘  â”‚                                   ğŸ”§ CONDITIONING PREPARATION                                           â”‚ â•‘
â•‘  â”‚                                                                                                         â”‚ â•‘
â•‘  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â•‘
â•‘  â”‚  â”‚ 1. TEXT ENCODING                                                                                  â”‚  â”‚ â•‘
â•‘  â”‚  â”‚                                                                                                   â”‚  â”‚ â•‘
â•‘  â”‚  â”‚    "Energetic electronic dance track..." â”€â”€â†’ T5 Encoder â”€â”€â†’ text_emb [1, seq, 768]               â”‚  â”‚ â•‘
â•‘  â”‚  â”‚                                                                                                   â”‚  â”‚ â•‘
â•‘  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â•‘
â•‘  â”‚                                                                                                         â”‚ â•‘
â•‘  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â•‘
â•‘  â”‚  â”‚ 2. VOICE EMBEDDING (if --style_of provided)                                                       â”‚  â”‚ â•‘
â•‘  â”‚  â”‚                                                                                                   â”‚  â”‚ â•‘
â•‘  â”‚  â”‚    reference.wav â”€â”€â†’ Resemblyzer â”€â”€â†’ voice_emb [1, 256]                                          â”‚  â”‚ â•‘
â•‘  â”‚  â”‚                                                                                                   â”‚  â”‚ â•‘
â•‘  â”‚  â”‚    (Optional with --separate_vocals)                                                              â”‚  â”‚ â•‘
â•‘  â”‚  â”‚    reference.wav â”€â”€â†’ Demucs â”€â”€â†’ vocals.wav â”€â”€â†’ ECAPA-TDNN â”€â”€â†’ ecapa_emb [1, 192]                 â”‚  â”‚ â•‘
â•‘  â”‚  â”‚                                                                                                   â”‚  â”‚ â•‘
â•‘  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â•‘
â•‘  â”‚                                                                                                         â”‚ â•‘
â•‘  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â•‘
â•‘  â”‚  â”‚ 3. STRUCTURE PLANNING (if --template provided)                                                    â”‚  â”‚ â•‘
â•‘  â”‚  â”‚                                                                                                   â”‚  â”‚ â•‘
â•‘  â”‚  â”‚    template="verse_chorus" + duration=30s                                                         â”‚  â”‚ â•‘
â•‘  â”‚  â”‚         â”‚                                                                                         â”‚  â”‚ â•‘
â•‘  â”‚  â”‚         â–¼                                                                                         â”‚  â”‚ â•‘
â•‘  â”‚  â”‚    CompositionPlanner â”€â”€â†’ [                                                                       â”‚  â”‚ â•‘
â•‘  â”‚  â”‚      {"type": "intro", "start": 0, "end": 4},                                                     â”‚  â”‚ â•‘
â•‘  â”‚  â”‚      {"type": "verse", "start": 4, "end": 12},                                                    â”‚  â”‚ â•‘
â•‘  â”‚  â”‚      {"type": "chorus", "start": 12, "end": 20},                                                  â”‚  â”‚ â•‘
â•‘  â”‚  â”‚      {"type": "verse", "start": 20, "end": 26},                                                   â”‚  â”‚ â•‘
â•‘  â”‚  â”‚      {"type": "outro", "start": 26, "end": 30},                                                   â”‚  â”‚ â•‘
â•‘  â”‚  â”‚    ]                                                                                              â”‚  â”‚ â•‘
â•‘  â”‚  â”‚                                                                                                   â”‚  â”‚ â•‘
â•‘  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â•‘
â•‘  â”‚                                                                                                         â”‚ â•‘
â•‘  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â•‘
â•‘  â”‚  â”‚ 4. PHONEME CONVERSION (if --lyrics provided)                                                      â”‚  â”‚ â•‘
â•‘  â”‚  â”‚                                                                                                   â”‚  â”‚ â•‘
â•‘  â”‚  â”‚    "Feel the bass drop" â”€â”€â†’ Gruut/eSpeak â”€â”€â†’ "fiËl Ã°É™ beÉªs drÉ’p"                                 â”‚  â”‚ â•‘
â•‘  â”‚  â”‚                                                                                                   â”‚  â”‚ â•‘
â•‘  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â•‘
â•‘  â”‚                                                                                                         â”‚ â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â•‘
â•‘                                                    â”‚                                                         â•‘
â•‘                                                    â–¼                                                         â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                     ğŸ”„ REVERSE DIFFUSION (DDPM/DDIM)                                         â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                                                              â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â•‘
â•‘  â”‚                                                                                                         â”‚ â•‘
â•‘  â”‚   zT ~ N(0, I)  [1, 128, H, W]     (Pure noise)                                                        â”‚ â•‘
â•‘  â”‚        â”‚                                                                                                â”‚ â•‘
â•‘  â”‚        â”‚                                                                                                â”‚ â•‘
â•‘  â”‚        â–¼                                                                                                â”‚ â•‘
â•‘  â”‚   â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—   â”‚ â•‘
â•‘  â”‚   â•‘                         FOR t = T, T-1, ..., 1, 0  (N steps, e.g. 50)                           â•‘   â”‚ â•‘
â•‘  â”‚   â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£   â”‚ â•‘
â•‘  â”‚   â•‘                                                                                                 â•‘   â”‚ â•‘
â•‘  â”‚   â•‘   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â•‘   â”‚ â•‘
â•‘  â”‚   â•‘   â”‚                        CLASSIFIER-FREE GUIDANCE (CFG)                                   â”‚   â•‘   â”‚ â•‘
â•‘  â”‚   â•‘   â”‚                                                                                         â”‚   â•‘   â”‚ â•‘
â•‘  â”‚   â•‘   â”‚   Îµ_cond = UNet(zâ‚œ, t, text_emb, voice_emb)      # Conditional prediction              â”‚   â•‘   â”‚ â•‘
â•‘  â”‚   â•‘   â”‚   Îµ_uncond = UNet(zâ‚œ, t, âˆ…, âˆ…)                   # Unconditional prediction            â”‚   â•‘   â”‚ â•‘
â•‘  â”‚   â•‘   â”‚                                                                                         â”‚   â•‘   â”‚ â•‘
â•‘  â”‚   â•‘   â”‚   ÎµÌ‚ = Îµ_uncond + cfg_scale * (Îµ_cond - Îµ_uncond)  # Guided noise                       â”‚   â•‘   â”‚ â•‘
â•‘  â”‚   â•‘   â”‚                                                                                         â”‚   â•‘   â”‚ â•‘
â•‘  â”‚   â•‘   â”‚   ğŸ’¡ cfg_scale=7.5: balances quality vs diversity                                      â”‚   â•‘   â”‚ â•‘
â•‘  â”‚   â•‘   â”‚                                                                                         â”‚   â•‘   â”‚ â•‘
â•‘  â”‚   â•‘   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â•‘   â”‚ â•‘
â•‘  â”‚   â•‘                                         â”‚                                                       â•‘   â”‚ â•‘
â•‘  â”‚   â•‘                                         â–¼                                                       â•‘   â”‚ â•‘
â•‘  â”‚   â•‘   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â•‘   â”‚ â•‘
â•‘  â”‚   â•‘   â”‚                        DDPM/DDIM STEP                                                    â”‚   â•‘   â”‚ â•‘
â•‘  â”‚   â•‘   â”‚                                                                                         â”‚   â•‘   â”‚ â•‘
â•‘  â”‚   â•‘   â”‚   # DDPM (stochastic):                                                                  â”‚   â•‘   â”‚ â•‘
â•‘  â”‚   â•‘   â”‚   zâ‚œâ‚‹â‚ = (1/âˆšÎ±â‚œ) * (zâ‚œ - (1-Î±â‚œ)/âˆš(1-á¾±â‚œ) * ÎµÌ‚) + Ïƒâ‚œ * noise                            â”‚   â•‘   â”‚ â•‘
â•‘  â”‚   â•‘   â”‚                                                                                         â”‚   â•‘   â”‚ â•‘
â•‘  â”‚   â•‘   â”‚   # DDIM (deterministic, faster):                                                       â”‚   â•‘   â”‚ â•‘
â•‘  â”‚   â•‘   â”‚   zâ‚œâ‚‹â‚ = âˆšá¾±â‚œâ‚‹â‚ * pred_zâ‚€ + âˆš(1-á¾±â‚œâ‚‹â‚) * ÎµÌ‚                                            â”‚   â•‘   â”‚ â•‘
â•‘  â”‚   â•‘   â”‚                                                                                         â”‚   â•‘   â”‚ â•‘
â•‘  â”‚   â•‘   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â•‘   â”‚ â•‘
â•‘  â”‚   â•‘                                         â”‚                                                       â•‘   â”‚ â•‘
â•‘  â”‚   â•‘                                         â–¼                                                       â•‘   â”‚ â•‘
â•‘  â”‚   â•‘   zâ‚œâ‚‹â‚ [1, 128, H, W]  â”€â”€â†’  (next iteration)                                                   â•‘   â”‚ â•‘
â•‘  â”‚   â•‘                                                                                                 â•‘   â”‚ â•‘
â•‘  â”‚   â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•   â”‚ â•‘
â•‘  â”‚        â”‚                                                                                                â”‚ â•‘
â•‘  â”‚        â–¼                                                                                                â”‚ â•‘
â•‘  â”‚   zâ‚€ [1, 128, H, W]  (Denoised latent)                                                                 â”‚ â•‘
â•‘  â”‚                                                                                                         â”‚ â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â•‘
â•‘                                                    â”‚                                                         â•‘
â•‘                                                    â–¼                                                         â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                     ğŸ”Š AUDIO DECODING                                                        â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                                                              â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â•‘
â•‘  â”‚                                                                                                         â”‚ â•‘
â•‘  â”‚   zâ‚€ [1, 128, H, W]                                                                                    â”‚ â•‘
â•‘  â”‚        â”‚                                                                                                â”‚ â•‘
â•‘  â”‚        â–¼                                                                                                â”‚ â•‘
â•‘  â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                                               â”‚ â•‘
â•‘  â”‚   â”‚   VAE Decoder       â”‚ â”€â”€â†’ mel [1, 128, T_mel]  (Mel spectrogram)                                   â”‚ â•‘
â•‘  â”‚   â”‚   (224M params)     â”‚                                                                               â”‚ â•‘
â•‘  â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                                               â”‚ â•‘
â•‘  â”‚        â”‚                                                                                                â”‚ â•‘
â•‘  â”‚        â–¼                                                                                                â”‚ â•‘
â•‘  â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                                               â”‚ â•‘
â•‘  â”‚   â”‚   HiFi-GAN Vocoder  â”‚ â”€â”€â†’ audio [1, samples]  (Waveform @ 32kHz)                                   â”‚ â•‘
â•‘  â”‚   â”‚   (mel â†’ waveform)  â”‚                                                                               â”‚ â•‘
â•‘  â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                                               â”‚ â•‘
â•‘  â”‚        â”‚                                                                                                â”‚ â•‘
â•‘  â”‚        â–¼                                                                                                â”‚ â•‘
â•‘  â”‚   ğŸ’¾ torchaudio.save("output.wav", audio, 32000)                                                       â”‚ â•‘
â•‘  â”‚                                                                                                         â”‚ â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â•‘
â•‘                                                                                                              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                    ğŸ“Š LDM INFERENCE PARAMETERS                                               â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                                                              â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â•‘
â•‘  â”‚         PARAMETER           â”‚          DEFAULT             â”‚              DESCRIPTION                  â”‚  â•‘
â•‘  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â•‘
â•‘  â”‚  num_steps                  â”‚  50                          â”‚  Number of denoising steps                â”‚  â•‘
â•‘  â”‚  cfg_scale                  â”‚  7.5                         â”‚  Classifier-free guidance strength        â”‚  â•‘
â•‘  â”‚  sampler                    â”‚  "ddim"                      â”‚  "ddpm" (slow) or "ddim" (fast)          â”‚  â•‘
â•‘  â”‚  eta                        â”‚  0.0                         â”‚  DDIM stochasticity (0=deterministic)    â”‚  â•‘
â•‘  â”‚  duration                   â”‚  30.0                        â”‚  Target duration in seconds               â”‚  â•‘
â•‘  â”‚  seed                       â”‚  None                        â”‚  Random seed for reproducibility          â”‚  â•‘
â•‘  â”‚                             â”‚                              â”‚                                           â”‚  â•‘
â•‘  â”‚  ğŸ’¡ More steps = better quality but slower                                                             â”‚  â•‘
â•‘  â”‚  ğŸ’¡ Higher CFG = more prompt-adherent but less diverse                                                 â”‚  â•‘
â•‘  â”‚  ğŸ’¡ DDIM 50 steps â‰ˆ DDPM 1000 steps in quality                                                         â”‚  â•‘
â•‘  â”‚                                                                                                        â”‚  â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â•‘
â•‘                                                                                                              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---

### train_v2.py - UÅ¼ycie

```bash
# Faza 1: VAE
python train_v2.py --phase 1 \
    --annotations ./data_v2/dataset.json \
    --audio_dir ./music/fma_small \
    --epochs 100 \
    --batch_size 8 \
    --device cuda

# Faza 2: Composition Planner
python train_v2.py --phase 2 \
    --annotations ./data_v2/dataset.json \
    --epochs 100

# Faza 3: LDM (wymaga VAE checkpoint)
python train_v2.py --phase 3 \
    --annotations ./data_v2/dataset.json \
    --audio_dir ./music/fma_small \
    --vae_checkpoint ./checkpoints_v2/vae_best.pt \
    --epochs 200 \
    --batch_size 4
```

### LDM v2 Conditioning (v3.1)

Model przyjmuje bogate kondycjonowanie przez `SectionConditioningModule`:

#### ğŸ“ Semantyczne kondycjonowanie

| Kondycja | Wymiar | Opis |
|----------|--------|------|
| `text_embed` | 768-dim | T5/CLAP text embedding â†’ 512-dim proj |
| `clap_audio_embedding` | 512-dim | CLAP audio â†’ 128-dim proj |
| `clap_text_embedding` | 512-dim | CLAP text â†’ 128-dim proj (fused z audio) |

#### ğŸ¤ Voice kondycjonowanie

| Kondycja | Wymiar | Opis |
|----------|--------|------|
| `voice_embedding` | 256-dim | Resemblyzer (z miksu audio) |
| `voice_emb_separated` | 192-dim | ECAPA-TDNN (z izolowanego wokalu) |

#### ğŸ¼ Struktura utworu

| Kondycja | Wymiar | Opis |
|----------|--------|------|
| `section_type` | one-hot 13 | intro/verse/pre_chorus/chorus/post_chorus/bridge/instrumental/solo/breakdown/buildup/drop/outro/unknown |
| `position` | float | 0.0-1.0 pozycja w utworze â†’ 128-dim MLP |
| `energy` | float | 0.0-1.0 energia segmentu â†’ 64-dim MLP |
| `tempo` | float | BPM (norm: (x-60)/140) â†’ 64-dim MLP |
| `key_idx` | int 0-23 | Tonacja (C/C#/.../B + maj/min) â†’ 64-dim embed |

#### ğŸ”Š Audio metadata (v3)

| Kondycja | Wymiar | Opis |
|----------|--------|------|
| `loudness` | float dB | GÅ‚oÅ›noÅ›Ä‡ (norm: (x+30)/30) â†’ 64-dim MLP |
| `has_vocals` | bool | 0/1 â†’ 32-dim embed |
| `sentiment_score` | float -1..1 | Sentyment â†’ 64-dim MLP |
| `genres` | List[List[str]] | Multi-hot genres â†’ mean â†’ 64-dim proj |
| `artists` | List[str] | Hash to 1000 buckets â†’ 64-dim embed |

#### ğŸ¥ Beat & Chord (v2)

| Kondycja | Wymiar | Opis |
|----------|--------|------|
| `num_beats` | int | Liczba beatÃ³w w segmencie |
| `beat_positions` | List[float] | Pozycje beatÃ³w â†’ BeatEmbedding â†’ 64-dim |
| `time_signature` | str | "4/4", "3/4" etc. |
| `current_chord` | str | "Cmaj", "Am7" etc. â†’ ChordEmbedding â†’ 64-dim |

#### ğŸ¤ Phoneme kondycjonowanie (v2)

| Kondycja | Wymiar | Opis |
|----------|--------|------|
| `phonemes_ipa` | str | IPA string â†’ PhonemeEncoder â†’ 128-dim proj |
| `phoneme_timestamps` | List[(phoneme, start, end)] | Timestamped IPA â†’ PhonemeTimestampEncoder â†’ 64-dim |

#### ğŸµ Pitch/F0 kondycjonowanie (v3)

| Kondycja | Wymiar | Opis |
|----------|--------|------|
| `f0` | [B, T] | Continuous F0 in Hz |
| `f0_coarse` | [B, T] | Discrete pitch bins (84 bins) |
| `f0_voiced_mask` | [B, T] bool | True=voiced, False=unvoiced |

#### ğŸ¤ Singing ekspresja (v3.1)

| Kondycja | Wymiar | Opis |
|----------|--------|------|
| `vibrato_rate` | float Hz | CzÄ™stotliwoÅ›Ä‡ vibrato |
| `vibrato_depth` | float cents | GÅ‚Ä™bokoÅ›Ä‡ vibrato |
| `vibrato_extent` | float 0-1 | Zakres vibrato |
| `breath_positions` | List[List[float]] | Pozycje oddechÃ³w â†’ BreathEncoder â†’ 32-dim |

#### ğŸ“Š Fusion dimensions

```
Base:     section(128) + position(128) + energy(64) + tempo(64) + key(64) + text(512)
          + loudness(64) + has_vocals(32) + sentiment(64) + genre(64) + artist(64) = 1248

Optional: + clap(128) + beat(64) + chord(64) + phoneme(128)
          + pitch(64) + vibrato(64) + breath(32) + phoneme_ts(64) = 1856

Final:    Fusion MLP â†’ output_dim (1024)
```

### UNetV2 - Kluczowe moduÅ‚y

```python
UNetV2(
    in_channels=128,        # latent_dim z VAE (v2: increased from 8)
    out_channels=128,
    model_channels=320,     # gÅ‚Ã³wny "size knob"
    num_res_blocks=2,
    attention_resolutions=[8, 4, 2],
    context_dim=768,        # text embedding dim
    num_heads=8,
    
    # v2: Voice conditioning
    voice_dim=256,              # Resemblyzer embedding
    ecapa_dim=192,              # ECAPA-TDNN embedding (voice_emb_separated)
    clap_dim=512,               # CLAP audio+text embedding
    use_voice_stream=True,      # VoiceStreamAttention
    use_dual_voice=True,        # Resemblyzer + ECAPA fusion
    
    # v2: Beat/Chord/Phoneme
    use_clap=True,
    use_beat=True,              # BeatEmbedding
    use_chord=True,             # ChordEmbedding
    use_phonemes=True,          # PhonemeEncoder
    
    # v3: Pitch conditioning
    use_pitch=True,
    f0_encoder_dim=64,
    
    # v3.1: Singing expression
    vibrato_encoder_dim=64,
    breath_encoder_dim=32,
    phoneme_timestamp_encoder_dim=64,
    
    # Performance
    use_gradient_checkpointing=True,
)
```

#### SectionConditioningModule - sekcje i metadane

```python
SectionConditioningModule(
    output_dim=1024,
    text_embed_dim=768,
    section_embed_dim=128,
    num_keys=24,            # C-B major/minor
    
    # v2 modules:
    use_clap=True,
    use_beat=True,
    use_chord=True,
    use_phonemes=True,
    
    # v3 modules:
    use_pitch=True,
    clap_dim=512,
    voice_dim=256,
)

# Forward przyjmuje 30+ parametrÃ³w kondycjonowania
section_cond.forward(
    text_embed,                     # [B, 768] lub [B, seq, 768]
    section_type,                   # List[str]
    position, energy, tempo,        # [B] floats
    key_idx,                        # [B] int 0-23
    loudness, has_vocals,           # [B] v3 metadata
    sentiment_score, genres, artists,
    clap_audio_embedding, clap_text_embedding,
    num_beats, beat_positions, time_signature, current_chord,
    phonemes_ipa, voice_embedding,
    f0, f0_coarse, f0_voiced_mask,
    vibrato_rate, vibrato_depth, vibrato_extent,
    breath_positions, phoneme_timestamps,
    segment_duration,
)
â†’ (conditioning [B, 1024], phoneme_durations or None)
```

---

## Struktura plikÃ³w

```
muzible-muze-ai/
â”œâ”€â”€ ğŸ“„ train_v2.py                 # Skrypt treningowy v2 (3-fazowy)
â”œâ”€â”€ ğŸ“„ inference_v2.py             # Generowanie muzyki z modelu
â”œâ”€â”€ ğŸ“„ build_dataset_v2.py         # Dataset builder v2 (peÅ‚na ekstrakcja)
â”‚
â”œâ”€â”€ ğŸ“ docs_v2/                    # Dokumentacja
â”‚   â””â”€â”€ ğŸ“„ DATASET_BUILDER.md      # PeÅ‚na dok. dataset buildera
â”‚
â”œâ”€â”€ ğŸ“ tools/
â”‚   â”œâ”€â”€ ğŸ“„ f0_extractor.py         # Ekstrakcja F0/pitch
â”‚   â””â”€â”€ ğŸ“„ analyze_metadata.py     # Analiza metadanych
â”‚
â”œâ”€â”€ ğŸ“ tools_v2/                   # NarzÄ™dzia v2
â”‚   â”œâ”€â”€ ğŸ“„ segment_annotator.py    # Detekcja segmentÃ³w (verse/chorus)
â”‚   â”œâ”€â”€ ğŸ“„ generate_artist_embeddings.py  # Generowanie voice embeddings
â”‚   â””â”€â”€ ğŸ“„ scan_mp3_folder.py      # Skanowanie folderÃ³w MP3
â”‚
â”œâ”€â”€ ğŸ“ models/
â”‚   â”œâ”€â”€ ğŸ“„ audio_vae.py            # Audio VAE (kompresja audio â†’ latent)
â”‚   â”œâ”€â”€ ğŸ“„ vocoder.py              # Vocoder (mel â†’ waveform)
â”‚   â””â”€â”€ ğŸ“„ voice_synthesis.py      # Voice cloning (XTTS, Demucs)
â”‚
â”œâ”€â”€ ğŸ“ models_v2/                  # ğŸ†• Architektura V2
â”‚   â””â”€â”€ ğŸ“„ latent_diffusion.py     # U-Net V2 + wszystkie encodery
â”‚
â”œâ”€â”€ ğŸ“ data/                       # Data v1 (legacy)
â”‚   â”œâ”€â”€ ğŸ“„ music_dataset.py        # PyTorch Dataset
â”‚   â””â”€â”€ ğŸ“„ training_dataset.json   # Dataset v1
â”‚
â”œâ”€â”€ ğŸ“ data_v2/                    # ğŸ†• Data v2
â”‚   â”œâ”€â”€ ğŸ“„ segmented_dataset.py    # SegmentedMusicDataset
â”‚   â””â”€â”€ ğŸ“„ *.json                  # Datasety v2
â”‚
â”œâ”€â”€ ğŸ“ music/
â”‚   â””â”€â”€ ğŸ“ fma_small/              # Pliki audio FMA
â”‚
â”œâ”€â”€ ğŸ“ checkpoints/                # Checkpointy v1
â”œâ”€â”€ ğŸ“ checkpoints_v2/             # ğŸ†• Checkpointy v2
â”‚
â””â”€â”€ ğŸ“ output/                     # Wygenerowane audio
```

---

## Scenariusze uÅ¼ycia

### Scenariusz 1: Trening od zera na wÅ‚asnych MP3

**Kiedy uÅ¼yÄ‡:** Masz wÅ‚asnÄ… kolekcjÄ™ MP3 i chcesz wytrenowaÄ‡ model od podstaw.

#### Krok 1: Przygotuj strukturÄ™ folderÃ³w

```bash
mkdir -p my_music/artist_name
cp ~/Music/*.mp3 my_music/artist_name/
```

#### Krok 2: Wygeneruj dataset

```bash
# PeÅ‚ny pipeline z analizÄ… audio, wokalu i voice embeddings
python build_dataset_v2.py \
    --audio_dir ./my_music \
    --output ./data_v2/my_dataset.json \
    --device cuda \
    --batch_size 4
```

**Co generuje:**
- `my_dataset.json` - metadane + prompty + wszystkie cechy audio (CLAP, voice, F0, etc.)
- `my_dataset.artist_embeddings.json` - Å›rednie voice embeddings per artysta

#### Krok 3: Trening VAE (Faza 1)

```bash
python train_v2.py \
    --phase 1 \
    --annotations ./data_v2/my_dataset.json \
    --audio_dir ./my_music \
    --epochs 50 \
    --batch_size 4 \
    --device cuda
```

**Czas:** ~2-4h na 1000 trackÃ³w (GPU RTX 3090)

#### Krok 4: Trening Diffusion (Faza 3)

```bash
python train_v2.py \
    --phase 3 \
    --annotations ./data_v2/my_dataset.json \
    --audio_dir ./my_music \
    --vae_checkpoint ./checkpoints/vae_epoch_50.pt \
    --epochs 100 \
    --batch_size 2 \
    --device cuda
```

**Czas:** ~8-12h na 1000 trackÃ³w (GPU RTX 3090)

---

### Scenariusz 2: Trening na FMA dataset

**Kiedy uÅ¼yÄ‡:** Masz FMA dataset i chcesz wytrenowaÄ‡ model.

#### Krok 1: Pobierz FMA (jeÅ›li nie masz)

```bash
# FMA Small (~8GB, 8000 trackÃ³w)
wget https://os.unil.cloud.switch.ch/fma/fma_small.zip
unzip fma_small.zip -d ./music/
```

#### Krok 2: Zbuduj dataset v2

```bash
python build_dataset_v2.py \
    --audio_dir ./music/fma_small \
    --output ./data_v2/fma_dataset.json \
    --device cuda \
    --batch_size 4
```

**Co generuje build_dataset_v2:**
| Pole | Opis | Å¹rÃ³dÅ‚o |
|------|------|--------|
| `has_vocals` | Czy utwÃ³r ma wokal | Whisper |
| `lyrics` | Transkrypcja tekstu | Whisper |
| `voice_embedding` | 256-dim wektor | Resemblyzer |
| `ecapa_embedding` | 192-dim wektor | ECAPA-TDNN |
| `clap_audio_embedding` | 512-dim | CLAP |
| `clap_text_embedding` | 512-dim | CLAP |
| `f0_contour` | Pitch contour | CREPE/pYIN |
| `vibrato_*` | Vibrato features | Custom |
| `breath_positions` | Breath timings | Custom |
| `phoneme_timestamps` | IPA + timing | Gruut/eSpeak |

#### Krok 3: Trening

```bash
# Faza 1: VAE
python train_v2.py --phase 1 \
    --annotations ./data_v2/fma_dataset.json \
    --audio_dir ./music/fma_small \
    --epochs 50

# Faza 3: LDM z voice conditioning
python train_v2.py --phase 3 \
    --annotations ./data_v2/fma_dataset.json \
    --audio_dir ./music/fma_small \
    --vae_checkpoint ./checkpoints_v2/vae_best.pt \
    --epochs 100
```

---

### Scenariusz 3: Dodanie nowych utworÃ³w do datasetu

**Kiedy uÅ¼yÄ‡:** Masz juÅ¼ dataset i chcesz dodaÄ‡ nowe tracki.

#### Metoda A: Rebuild z nowym folderem

```bash
# Dodaj nowe MP3 do folderu
cp ~/new_music/*.mp3 ./music/fma_small/new/

# Przebuduj dataset (wykryje nowe pliki)
python build_dataset_v2.py \
    --audio_dir ./music/fma_small \
    --output ./data_v2/dataset_updated.json \
    --device cuda
```

#### Metoda B: Merge JSON

```python
import json

# Wczytaj istniejÄ…cy
with open('data_v2/dataset.json') as f:
    dataset = json.load(f)

# Wczytaj nowe
with open('data_v2/new_tracks.json') as f:
    new_tracks = json.load(f)

# PoÅ‚Ä…cz (sprawdÅº duplikaty po audio_path)
existing_paths = {t['audio_path'] for t in dataset}
for track in new_tracks:
    if track['audio_path'] not in existing_paths:
        dataset.append(track)

# Zapisz
with open('data_v2/dataset_merged.json', 'w') as f:
    json.dump(dataset, f, indent=2)
```

#### Metoda C: Kontynuuj trening (fine-tuning)

```bash
# Dotrenuj na nowych danych
python train_v2.py --phase 3 \
    --annotations ./data_v2/dataset_merged.json \
    --audio_dir ./music \
    --vae_checkpoint ./checkpoints_v2/vae_best.pt \
    --ldm_checkpoint ./checkpoints_v2/ldm_epoch_100.pt \
    --epochs 20  # Mniej epok dla fine-tuningu
```

---

## Inference - generowanie muzyki

### Podstawowe generowanie

```bash
python inference_v2.py \
    --prompt "Energetic electronic dance track with heavy bass" \
    --output ./output/edm_track.wav \
    --duration 30 \
    --device cuda
```

### Ze stylem artysty (voice embedding)

```bash
python inference_v2.py \
    --prompt "Melodic hip-hop beat" \
    --style_of "Artist Name" \
    --output ./output/artist_style.wav
```

### Z klonowaniem gÅ‚osu

```bash
python inference_v2.py \
    --prompt "Upbeat pop song" \
    --voice_clone "Artist Name" \
    --lyrics "Here are the lyrics to sing..." \
    --output ./output/cloned_voice.wav
```

### Z szablonem struktury

```bash
python inference_v2.py \
    --prompt "Energetic pop with female vocals" \
    --template verse_chorus \
    --duration 120 \
    --output ./output/structured_song.wav
```

### Wszystkie opcje

```bash
python inference_v2.py --help

# GÅ‚Ã³wne opcje:
#   --prompt TEXT          Prompt opisujÄ…cy muzykÄ™
#   --output PATH          ÅšcieÅ¼ka wyjÅ›ciowa (def: ./output/generated.wav)
#   --duration FLOAT       DÅ‚ugoÅ›Ä‡ w sekundach (def: 30)
#   --cfg_scale FLOAT      Classifier-free guidance (def: 7.5)
#   --num_steps INT        Kroki denoising (def: 50)
#   --template NAME        Szablon struktury (verse_chorus, etc.)
#
# Voice conditioning:
#   --style_of NAME/PATH   Voice embedding artysty lub plik .wav
#
# Voice cloning:
#   --voice_clone NAME     Artysta do sklonowania gÅ‚osu
#   --voice_clone_samples PATH  Folder/plik z samplami gÅ‚osu
#   --lyrics TEXT          Tekst do zaÅ›piewania
#   --language CODE        Kod jÄ™zyka (pl, en, de, etc.)
```

---

## SzczegÃ³Å‚owy opis plikÃ³w

### ğŸ“„ `train_v2.py`

**Cel:** GÅ‚Ã³wny skrypt treningowy v2 dla VAE, Composition Planner i LDM.

**Fazy treningu:**
1. **Faza 1 (VAE):** Audio â†’ Mel â†’ Latent â†’ Mel (rekonstrukcja)
2. **Faza 2 (Composition Planner):** Track features â†’ Composition plan
3. **Faza 3 (LDM):** Noise â†’ UNet V2 (conditioned) â†’ Latent â†’ VAE â†’ Audio

**Kluczowe parametry:**
```python
# VAE
latent_dim = 128      # v2: zwiÄ™kszone z 8
sample_rate = 32000   # v2: 32kHz

# LDM
cfg_dropout = 0.1     # Classifier-free guidance dropout
voice_dropout = 0.1   # Voice conditioning dropout
```

---

### ğŸ“„ `inference_v2.py`

**Cel:** Generowanie muzyki z wytrenowanego modelu v2.

**GÅ‚Ã³wne funkcje:**
- `generate_composition_plan()` - planowanie struktury utworu
- `generate_section_audio()` - generacja pojedynczej sekcji
- `generate_full_song()` - generacja peÅ‚nego utworu sekcja po sekcji

**Pipeline:**
1. Prompt â†’ T5/CLAP Encoder â†’ text embedding
2. (opcjonalnie) Voice sample â†’ Resemblyzer/ECAPA â†’ voice embedding
3. (opcjonalnie) Lyrics â†’ Gruut/eSpeak â†’ phonemes IPA
4. Template â†’ CompositionPlanner â†’ struktura sekcji
5. Per sekcja: Noise + embeddings â†’ UNet V2 denoising â†’ Latent
6. Latent â†’ VAE Decoder â†’ Mel spectrogram
7. Mel â†’ HiFi-GAN â†’ Audio WAV
8. Concat all sections â†’ Final audio

---

### ğŸ“„ `build_dataset_v2.py`

**Cel:** PeÅ‚na ekstrakcja cech z plikÃ³w audio.

**Ekstrahuje:**
- Metadane (ID3 tags)
- Audio features (librosa: tempo, key, energy, etc.)
- Voice embeddings (Resemblyzer 256-dim + ECAPA-TDNN 192-dim)
- CLAP embeddings (audio 512-dim + text 512-dim)
- Pitch/F0 (CREPE/pYIN)
- Vibrato, breath, phoneme features
- Segment detection (verse/chorus/bridge)
- Lyrics transcription (Whisper)

**WyjÅ›cie:** JSON z polami v3.1 (patrz diagram DATASET powyÅ¼ej)

---

### ğŸ“„ `models_v2/latent_diffusion.py`

**Cel:** UNet V2 + wszystkie moduÅ‚y kondycjonowania.

**GÅ‚Ã³wne klasy:**
- `UNetV2` - gÅ‚Ã³wny model diffusion
- `SectionConditioningModule` - fusion wszystkich kondycji
- `VoiceStreamAttention` - gated cross-attention dla voice
- `VoiceEmbeddingFusion` - fuzja Resemblyzer + ECAPA
- `PitchEncoder`, `VibratoEncoder`, `BreathEncoder` - enkodery cech
- `BeatEmbedding`, `ChordEmbedding`, `PhonemeEncoder` - enkodery v2

---

### ğŸ“„ `models/audio_vae.py`

**Cel:** Kompresja audio do przestrzeni latentnej.

**Architektura v2:**
```
Mel [1, 128, T] â†’ Encoder â†’ Î¼, Ïƒ â†’ z [128, H, W] â†’ Decoder â†’ Mel [1, 128, T]
```
```

**Parametry:**
- `latent_dim = 8` - wymiar kanaÅ‚Ã³w latent
- `channels = [64, 128, 256, 512]` - kanaÅ‚y encodera
- `n_mels = 128` - liczba mel filterbanks (v2: zwiÄ™kszone z 80)

**Loss:**
```python
loss = reconstruction_loss + beta * kl_divergence + stft_loss
```

---

### ğŸ“„ `models/text_encoder.py`

**Cel:** Enkodowanie promptÃ³w tekstowych.

**Backendy:**
- `T5TextEncoder` - Flan-T5 (768-dim, dobry dla dÅ‚ugich opisÃ³w)
- `CLAPTextEncoder` - CLAP (specjalnie trenowany na audio-text)
```python
# 1. Wyekstrahuj wokal
extractor = VoiceExtractorFromSong()
vocals_path = extractor.extract_vocals("song.mp3")

# 2. Zarejestruj gÅ‚os
synth = VoiceSynthesizer(backend="coqui")
synth.register_voice("artist", vocals_path)

# 3. Syntetyzuj nowy tekst
audio = synth.synthesize("New lyrics...", voice="artist")
```

---

### ğŸ“„ `data/music_dataset.py`

**Cel:** PyTorch Dataset dla treningu.

**Zwraca batch:**
```python
{
    'audio': torch.Tensor,           # [num_samples]
    'prompt': str,                   # "Energetic rock song..."
    'voice_embedding': torch.Tensor, # [256] lub None
    'lyrics': str,                   # "Transcribed lyrics..."
    'has_vocals': bool,
    'text_sentiment': str,           # "positive"
    'track_id': int,
    'artist': str,
}
```

**Custom collate_fn:**
- Stackuje tensory
- Grupuje stringi w listy
- ObsÅ‚uguje None w voice_embedding

---

## FAQ & Troubleshooting

### â“ Dlaczego `/var/folders/...` w Å›cieÅ¼ce do wokali?

**Pytanie:** `Vocals saved to: /var/folders/fg/frwh54994k9gy6h5y_tc1_940000gn/T/2_Food_vocals.wav`

**OdpowiedÅº:** To jest **domyÅ›lny folder tymczasowy macOS** (`tempfile.gettempdir()`).

`VoiceExtractorFromSong` domyÅ›lnie zapisuje wyekstrahowane wokale do folderu tymczasowego systemu, ktÃ³ry na macOS to:
```
/var/folders/XX/XXXX/T/
```

**RozwiÄ…zanie:** Ustaw wÅ‚asny `output_dir`:

```python
extractor = VoiceExtractorFromSong(
    output_dir="./data/separated_vocals"  # StaÅ‚y folder
)
```

Lub podczas budowania datasetu z `build_dataset_v2.py` z flagÄ… `--separate_vocals`.

---

### â“ Trening jest bardzo wolny na CPU

**Problem:** Trening na CPU zajmuje godziny nawet dla kilku trackÃ³w.

**RozwiÄ…zania:**
1. UÅ¼yj GPU: `--device cuda`
2. Zmniejsz batch size: `--batch_size 1`
3. Zmniejsz liczbÄ™ trackÃ³w: `--max_tracks 10`
4. UÅ¼yj mixed precision (auto na GPU)

---

### â“ `CUDA out of memory`

**Problem:** GPU nie ma wystarczajÄ…co pamiÄ™ci.

**RozwiÄ…zania:**
1. Zmniejsz batch size: `--batch_size 1`
2. UÅ¼yj gradient checkpointing (domyÅ›lnie wÅ‚Ä…czone)
3. UÅ¼yj mniejszego modelu VAE
4. SkrÃ³Ä‡ duration: zmieÅ„ w kodzie `duration=5.0`

---

### â“ Voice cloning brzmi robotycznie

**Problem:** XTTS generuje sztuczny gÅ‚os.

**RozwiÄ…zania:**
1. UÅ¼yj dÅ‚uÅ¼szego sampla gÅ‚osu (>30s)
2. Upewnij siÄ™ Å¼e sample ma czysty wokal (bez instrumentÃ³w)
3. UÅ¼yj ElevenLabs zamiast Coqui (lepsza jakoÅ›Ä‡, pÅ‚atne)

---

### â“ Whisper nie wykrywa wokalu

**Problem:** `has_vocals: false` dla utworÃ³w z wokalem.

**Przyczyny:**
1. Instrumental zbyt gÅ‚oÅ›ny
2. Wokal w jÄ™zyku niewspieranym
3. Za krÃ³tki fragment analizowany

**RozwiÄ…zania:**
1. UÅ¼yj `--whisper_full` (analizuj caÅ‚y utwÃ³r)
2. UÅ¼yj wiÄ™kszego modelu: `--whisper_model medium`
3. Najpierw odseparuj wokal: `--separate_vocals`

---

### â“ Brak moduÅ‚u `speechbrain`

**Warning:** `No module named 'speechbrain'`

**RozwiÄ…zanie:** System automatycznie uÅ¼ywa `resemblyzer` jako fallback. JeÅ›li chcesz SpeechBrain:
```bash
pip install speechbrain
```

---

## ğŸ“Š Model Size Configuration

### Parametry konfiguracji rozmiaru modelu

| Parametr | WpÅ‚yw | Opis |
|----------|-------|------|
| `latent_dim` | Minimalny (~3M) | Wymiar przestrzeni latentnej VAE |
| `model_channels` | **KLUCZOWY** | Bazowa szerokoÅ›Ä‡ kanaÅ‚Ã³w UNet - gÅ‚Ã³wny "size knob" |

### Tabela rozmiarÃ³w modeli

| Config | latent_dim | model_channels | VAE | UNet | **Total** |
|--------|-----------|----------------|-----|------|-----------|
| Test/Dev | 128 | 256 | 224M | 722M | **~1B** |
| Production Default | 128 | 320 | 224M | 1.1B | **~1.3B** |
| Large Production | 128 | 512 | 224M | 2.8B | **~3B** |
| XL Production | 256 | 512 | 228M | 2.8B | **~3B** |
| XXL (multi-billion) | 256 | 768 | 228M | 6.1B | **~6.4B** |

### Wnioski

- **`latent_dim=128` jest wystarczajÄ…cy** - rÃ³Å¼nica miÄ™dzy 128 a 256 to tylko ~3M parametrÃ³w w VAE (~1.5% rÃ³Å¼nicy)
- **`model_channels` to prawdziwy "size knob"** - zwiÄ™kszenie z 320â†’512 daje skok z 1.1Bâ†’2.8B
- Dla **kilku miliardÃ³w parametrÃ³w**: `model_channels=512-768` jest kluczowe

### Rekomendacje

| Zastosowanie | Konfiguracja | Rozmiar |
|--------------|--------------|---------|
| Lokalne testy/dev | `latent_dim=128, model_channels=256` | ~1B |
| Produkcja standardowa | `latent_dim=128, model_channels=320` | ~1.3B |
| DuÅ¼y model produkcyjny | `latent_dim=128, model_channels=512` | ~3B |
| Bardzo duÅ¼y model | `latent_dim=256, model_channels=768` | ~6.4B |

### PrzykÅ‚ad konfiguracji w kodzie

```python
# Test/Dev (~1B)
unet = UNetV2(
    in_channels=128,
    out_channels=128,
    model_channels=256,  # mniejszy dla szybkiego testowania
    context_dim=768,
)

# Production (~3B)
unet = UNetV2(
    in_channels=128,
    out_channels=128,
    model_channels=512,  # wiÄ™kszy dla jakoÅ›ci
    context_dim=768,
)
```

### AudioVAE - PeÅ‚na konfiguracja

**Parametry `AudioVAE.__init__`:**

| Parametr | Default | Opis |
|----------|---------|------|
| `sample_rate` | 32000 | v2: 32kHz (v1: 22050) |
| `n_mels` | 128 | Liczba mel bins |
| `n_fft` | 1024 | FFT window size |
| `hop_length` | 320 | 10ms hop @ 32kHz |
| `latent_dim` | 128 | v2: zwiÄ™kszone z 8 |
| `channels` | None | Auto-select z `LATENT_CONFIGS` |
| `use_stft_loss` | True | Multi-Resolution STFT Loss |
| `use_checkpoint` | False | Gradient checkpointing (oszczÄ™dnoÅ›Ä‡ VRAM) |

**Auto-select channels (`LATENT_CONFIGS`):**

| latent_dim | channels (auto) | Rozmiar VAE |
|------------|-----------------|-------------|
| 8 | [64, 128, 256, 512] | **55M** |
| 32 | [64, 128, 256, 512] | **56M** |
| 64 | [96, 192, 384, 768] | **125M** |
| 128 | [128, 256, 512, 1024] | **224M** |

**Custom channels - peÅ‚na skala:**

| Config | channels | Rozmiar |
|--------|----------|---------|
| v2 Light | [64, 128, 256, 512] | **57M** |
| v2 Default | [128, 256, 512, 1024] | **224M** |
| v2 Heavy | [256, 512, 1024, 2048] | **889M** |

**PrzykÅ‚ady konfiguracji VAE:**

```python
# Default v2 (224M) - zalecane
vae = AudioVAE(latent_dim=128)

# Light (57M) - szybkie testy
vae = AudioVAE(latent_dim=128, channels=[64, 128, 256, 512])

# Heavy (889M) - maksymalna jakoÅ›Ä‡ rekonstrukcji
vae = AudioVAE(latent_dim=128, channels=[256, 512, 1024, 2048])

# Z gradient checkpointing (mniej VRAM)
vae = AudioVAE(latent_dim=128, use_checkpoint=True)
```

---

## Wymagania

```txt
# Core
torch>=2.0
torchaudio>=2.0
transformers>=4.30
einops
vocos

# Audio processing
librosa
soundfile
mutagen

# Whisper (opcjonalne)
faster-whisper  # lub openai-whisper

# Voice embeddings (jedno z):
resemblyzer        # lekkie (256-dim)
speechbrain        # lepsze (192-dim ECAPA-TDNN)

# Voice cloning (opcjonalne)
TTS                # Coqui XTTS v2
demucs             # Separacja wokali

# LLM (opcjonalne)
openai             # GPT-4
requests           # Ollama
```

---

## Licencja

MIT License - uÅ¼yj do wÅ‚asnych projektÃ³w!

âš ï¸ **Uwaga prawna:** Voice cloning moÅ¼e naruszaÄ‡ prawa do wizerunku gÅ‚osu artystÃ³w. UÅ¼ywaj tylko z wÅ‚asnym gÅ‚osem lub za zgodÄ… wÅ‚aÅ›ciciela.

---

## PowiÄ…zane dokumenty

- ğŸ“˜ [Dataset Builder - peÅ‚na dokumentacja](docs_v2/DATASET_BUILDER.md)

---

*Dokumentacja wygenerowana: 12 grudnia 2025*
